# FNTX AI - Agentic Options Trader

## ⚠️ CRITICAL: READ THIS FIRST ⚠️

**BEFORE DOING ANYTHING, YOU MUST:**

**ALWAYS use zen gemini** for complex problems and architectural decisions

**ALWAYS check Context7** for library documentation and best practices

**NEVER jump straight to coding** - Research → Plan → Implement is MANDATORY

**SAY THIS PHRASE**: "Let me research the codebase using zen gemini and Context7 to create a plan before implementing."

## House Rules 

Please adhere to this folder structure and allocate new files according to this framework:

01_backend	All server-side application code, APIs, business logic, and backend services.

02_frontend	All client-side code, user interface components, static assets, and web app resources.

03_database	Database schema definitions, migrations, seed data scripts, and DB configuration files.

04_data	Working data files: raw, processed, imported/exported datasets, and temporary data.

05_docs	Project documentation, guides, architecture diagrams, and reference materials.

06_scripts	Scripts for data collection, ETL (Extract, Transform, Load), automation, and processing.

07_tools	Utility tools, helper scripts, and supporting binaries used across the project.

08_logs	Log files and output generated by the application or scripts (for debugging/tracking).

09_onetime	One-off scripts, migration helpers, or files/scripts used for single-use tasks.

10_runtime	Runtime-generated files, sockets, caches, or other ephemeral execution artifacts.

11_venv	Python virtual environment directory (auto-generated, do not edit manually).

12_rl_trading for implementing a RL trading dashboard 

fntx-cli developing a CLI for automated options trading (/home/info/fntx-ai-v1/fntx-cli/business plan.txt)

### IMPORTANT FILE TRACKING RULE:

**After every prompt response that creates new files, you MUST in the prompt, explain and describes:**
1. The exact file path and name of each file created
2. Which numbered folder (and their subfolders) it was allocated to and why 
3. The purpose and type of the file (e.g., documentation, script, configuration)
4. How it interfaces with other files 

Example format:
```
## Files Created:
- `/home/info/fntx-ai-v1/09_onetime/check_db_stats.py` - One-time script to check database statistics
- `/home/info/fntx-ai-v1/05_docs/DATABASE_SCHEMAS.md` - Documentation for database schema relationships
```

This ensures proper organization and easy tracking of all project components.

## Introduction

This CLAUDE.md outlines the architecture, methodologies, and implementation details of an advanced AI-driven options trading system. Building upon the foundational FNTX AI project, this enhanced system integrates cutting-edge deep reinforcement learning techniques, particularly ensemble strategies and massively parallel simulations, adapted from recent academic research in automated stock trading. The primary objective is to develop a highly intelligent, agentic options trader capable of consistently generating significant daily profits, targeting a profit of six to eight trades out of ten, with an ultimate goal of achieving a couple million Hong Kong dollars (HKD) or a couple thousand US dollars (USD) per day, or at least a couple hundred USD daily.

The system emphasizes practical, material, and trackable iterations, incorporating principles from research papers such as Paper 1 and Paper 2. While these papers primarily focus on stock and cryptocurrency trading, their core methodologies, particularly regarding reinforcement learning, ensemble techniques, and efficient simulation environments, are universally applicable and will be meticulously adapted for the nuances of options trading.

## 1. FNTX AI Project Overview

The FNTX AI project is an automated trading system designed to execute options strategies. Its core components include a React with Vite frontend, a Python FastAPI backend with AI agents, a PostgreSQL database with trading, portfolio, and options data, and IBKR integration for live trading, complemented by ThetaTerminal for historical data.

### 1.1 Current Architecture

The FNTX AI system, as described in its `README.md` and further detailed in project-specific instructions, is structured around several core components:

*   **Frontend**: A React and TypeScript-based user interface for real-time chat, trading, and analytics, built with Vite.
*   **Main Backend**: A Python FastAPI server handling core trading operations and housing AI agents.
*   **Chat Backend**: Integrates OpenAI GPT-4 for natural language interaction and trading conversations.
*   **AI Agents**: Includes a variety of agentic executors that perform different roles in a seamless, coherent, and logical manner, forming a team of highly intelligent, effective agents with expertise in the options trading field. These agents are located in the `backend/` directory.
*   **IBKR Integration**: Facilitates real-time market data and trade execution through Interactive Brokers.
*   **Database**: A PostgreSQL database storing trading, portfolio, and options data. It currently holds 215 million rows of SPY options OHLC data and is approximately 112GB in size. An active background process continuously downloads Greeks/IV data.
*   **Historical Data**: Utilizes ThetaTerminal for historical options data.
*   **Technology Stack**: Leverages React, TypeScript, Vite, Tailwind CSS, FastAPI, Python, SQLite (for development), OpenAI GPT-4, and WebSockets for real-time communication.

### 1.2 Trading Strategy and Risk Management

The current trading strategy focuses on daily SPY options selling, incorporating automated risk management with a 3x stop-loss and 50% take-profit. The system also accounts for strategic waiting periods and real-time market condition analysis. It features a multi-tiered AI architecture (Strategic + Tactical layers) and aims for explainable AI with clear reasoning for decisions. Performance tracking includes metrics like DPI, TVPI, RVPI, Win Rate, and Average Return.

## 2.DRL for Options Trading: Ensemble Strategies and Parallel Simulation

To elevate the FNTX AI system to an institutional grade, we will integrate advanced deep reinforcement learning (DRL) methodologies, drawing heavily from the principles outlined in the provided research papers. The core idea is to leverage ensemble learning and massively parallel simulations to enhance the system's capabilities. The papers model stock trading as a Markov Decision Process (MDP), which is highly applicable to options trading.

### 2.2 Ensemble Learning for Robustness

Paper 1 highlights the benefits of an ensemble strategy using deep reinforcement learning, combining Proximal Policy Optimization (PPO), Advantage Actor Critic (A2C), and Deep Deterministic Policy Gradient (DDPG). This approach significantly enhances robustness and reliability by allowing the trading strategy to adjust to diverse market situations. For options trading, this ensemble approach is even more critical due to the higher complexity and volatility of options markets.

We will implement an ensemble of DRL agents, each potentially trained with different algorithms (e.g., PPO, A2C, DDPG, or other suitable algorithms for continuous action spaces) and/or on different subsets of historical options data or market conditions. The ensemble will combine the strengths of these individual agents, for instance, by voting on actions or weighted averaging action probabilities, to make more robust trading decisions. This will help mitigate policy instability, a known challenge in RL.

### 2.3 Parallel Simulation for Efficiency

Paper 2 emphasizes the importance of massively parallel simulations on GPUs to overcome the sampling bottleneck in DRL training. This is crucial for financial tasks due to the high computational demands and the need for extensive data sampling. For options trading, which involves even more complex state and action spaces and potentially larger datasets (8 years of historical options data for 20 tickers), parallel simulation will be indispensable.

We will develop vectorized environments for options trading that can simulate thousands of parallel market environments on GPUs. This will drastically improve the sampling speed, allowing for more efficient training of the DRL agents and the ensemble model. The existing FNTX AI project\'s `scripts/data` directory, with its `start_enhanced_download.sh` and `status_enhanced_download.sh` scripts, suggests a capability for handling large datasets, which aligns with the need for extensive historical options data. The `database` directory also indicates a structure for managing this data.

## 3. Enhanced Agent Architecture

The current FNTX AI project already features a multi-agent architecture. To meet the user\'s requirements and integrate the advanced DRL methodologies, we will enhance this architecture with additional specialized agents, most notably the \'Timer\' agent, and refine the roles of existing agents.

### 3.1 The Timer Agent

The user specifically requested a \'Timer\' agent to time how long to wait after the market opens before trading. This agent will play a crucial role in managing the timing aspect of trades, ensuring that the system adheres to predefined waiting periods or market conditions before initiating any trading activity. This is particularly important in options trading where initial market movements can be highly volatile.

The `Timer` agent will:

*   **Monitor Market Open**: Accurately detect the market open time.
*   **Implement Waiting Periods**: Enforce a configurable waiting period (e.g., 15 minutes, 30 minutes) after market open before allowing any trading signals to be acted upon. This period can be dynamically adjusted based on market volatility or specific strategies.
*   **Provide Market Context**: Potentially analyze initial market movements during the waiting period to provide additional context or flags to the `Planner` agent, influencing subsequent trading decisions.
*   **Act as a Referee**: As described by the user, the `Timer` agent will act as a \'referee,\' ensuring that trading rules related to timing are strictly followed, preventing premature or ill-timed entries.

### 3.2 Refined Trading Agents

The existing agents will be enhanced to incorporate the DRL-based ensemble strategies and handle the complexities of options trading.

*   **Planner Agent (Strategic Layer)**: This agent will be responsible for the higher-level strategic decisions. It will receive inputs from the `Timer` agent, real-time market data, and the outputs from the DRL ensemble model. Its responsibilities will include:
    *   **Strategy Selection**: Based on market conditions and DRL ensemble outputs, select the optimal options trading strategy (e.g., iron condor, vertical spread, naked call/put) for the day or trading period.
    *   **Position Sizing**: Determine appropriate position sizes based on risk parameters, account balance, and volatility, as highlighted in the user\'s request for risk position size.
    *   **Trade Rule Nuance**: Incorporate nuanced trade rules, such as the suggested "15 delta plus certain constraints such as timing or risk position size." This will involve the `Planner` agent translating the DRL model\'s high-level decisions into specific options contracts and parameters, considering factors like implied volatility, time decay, and liquidity.
    *   **RLHF Feedback Integration**: The `Planner` will also integrate the RLHF (Reinforcement Learning from Human Feedback) mechanism. This means that human feedback on trade decisions or outcomes will be used to refine the DRL models, allowing for continuous self-learning and improvement, as mentioned by the user.

*   **Executor Agent (Tactical Layer)**: This agent will be responsible for the precise execution of trades based on the `Planner`\'s instructions. Its functions will include:
    *   **Order Management**: Sending orders to the Interactive Brokers API, ensuring correct strike prices, expirations, and order types (e.g., limit orders with specific price adjustments).
    *   **Real-time Monitoring**: Continuously monitoring open positions and market conditions to manage risk, including automated stop-loss (3x) and take-profit (50%) mechanisms, as currently implemented in FNTX AI.
    *   **Slippage and Transaction Cost Management**: Optimizing order placement to minimize slippage and account for transaction costs, which are crucial in options trading.

### 3.3 Data Requirements and Preprocessing

The user\'s intention to download "eight years of historical options data for like maybe 20 tickers" is critical for training the neural networks. This extensive dataset will be preprocessed to extract relevant features for the DRL models.

*   **Historical Options Data**: This will include historical bid/ask prices, open interest, volume, implied volatility, and Greeks (Delta, Gamma, Theta, Vega, Rho) for various strike prices and expiration dates. The SPY ticker is already a focus, and the additional 19 tickers will expand the training scope.
*   **Underlying Asset Data**: Historical price data (OHLCV) for the underlying assets (e.g., SPY and the other 19 tickers) will be integrated.
*   **Technical Indicators**: Various technical indicators (e.g., MACD, RSI, Bollinger Bands) will be computed from the underlying asset data to enrich the state space for the DRL models.
*   **Market Microstructure Data**: If available, higher-frequency data like Level 2 order book data could be incorporated to capture finer market dynamics, although this might significantly increase data volume and complexity.
*   **Data Storage and Management**: The `database` directory in the FNTX AI project will be utilized and potentially scaled to handle the large volume of historical options data. Efficient data retrieval and processing will be essential for training.

### 3.4 Neural Network Training and Classification Model

The core of the intelligent agentic options trader will be neural networks trained on the historical data. The user\'s request to "elaborate on exactly how to run the classification model" suggests a need for clear guidance on the training process.

*   **DRL Model Training**: The ensemble of DRL agents (PPO, A2C, DDPG, etc.) will be trained using the processed historical options data within the massively parallel simulation environment. The training objective will be to maximize the cumulative reward (portfolio value change) while adhering to risk constraints.
    *   **State Representation**: The input to the neural networks will be the comprehensive state vector, including all the features derived from options data, underlying asset data, and technical indicators.
    *   **Action Output**: The output of the neural networks will be the actions, which, for options, could be continuous values representing changes in position or probabilities over a discrete set of predefined options strategies.
    *   **Reward Function**: The reward function will be carefully designed to incentivize profitable and risk-managed options trading, aligning with the user\'s profit targets and risk controls.
*   **Classification Model for Trade Signals**: Beyond the DRL models, a separate classification model can be employed to generate trade signals or confirm DRL-generated actions. This model could be trained to classify market conditions into categories like "buy call," "sell put," "neutral," etc., based on historical data and successful trade patterns. This would act as a filter or a secondary validation layer for the DRL agent\'s decisions.
    *   **Input Features**: Features for the classification model would include a subset of the state variables, focusing on those most indicative of profitable options trading opportunities (e.g., implied volatility changes, price action, delta).
    *   **Output Classes**: The output would be a classification of potential trade actions or market outlooks.
    *   **Training**: Supervised learning techniques would be used to train this classification model, with historical profitable trades serving as positive examples.

## 4. Practical Implementation and Iteration

Achieving the end goal of consistent daily profits requires a practical, iterative approach, focusing on measurable metrics and continuous improvement.

### 4.1 RLHF Feedback Mechanism

The user\'s emphasis on "applying a RLHF feedback mechanism" is crucial for continuous self-learning. This involves:

*   **Human Oversight and Feedback**: Human traders or analysts will review the AI\'s trade decisions and outcomes. Their feedback (e.g., "good trade," "bad trade," "should have waited," "position too large") will be collected.
*   **Reward Model Training**: This human feedback will be used to train a reward model, which learns to predict human preferences for different trading outcomes. This reward model then provides a more nuanced reward signal to the DRL agents during training, guiding them towards strategies that are not only profitable but also align with human expert judgment.
*   **Iterative Refinement**: The DRL agents will be continuously retrained with the refined reward signals, leading to an iterative improvement cycle where the AI learns from its successes and failures, guided by human expertise.

### 4.2 Performance Tracking and Optimization

The FNTX AI project already tracks key performance metrics. These will be critical for monitoring progress and optimizing the system.

*   **Profitability Metrics**: Beyond the existing Win Rate and Average Return, specific options-related metrics like average premium collected, average profit per contract, and profit factor will be tracked.
*   **Risk Metrics**: Enhanced risk tracking will include metrics like maximum drawdown, Value at Risk (VaR), and stress testing under various market scenarios.
*   **Sharpe Ratio**: As highlighted in the research papers, the Sharpe ratio will be a key metric for evaluating risk-adjusted returns, especially for the ensemble strategy.
*   **A/B Testing**: Different DRL models, ensemble configurations, or trade rules can be A/B tested in simulation to identify the most effective strategies before deployment.

### 4.3 Institutional-Grade Deployment Considerations

To make the system "institutional grade deployable," several factors need to be considered:

*   **Scalability**: The system must be able to handle increased data volume and trading frequency. The use of Docker containers and PostgreSQL for production, as mentioned in the FNTX AI `README.md`, aligns with this.
*   **Robustness and Fault Tolerance**: Implementing robust error handling, logging, and backup mechanisms to ensure continuous operation even under adverse conditions.
*   **Security and Compliance**: Adhering to strict security protocols for API key management, data encryption, and regulatory compliance (e.g., audit trails, KYC/AML integration).
*   **Low Latency Execution**: For options trading, especially for short-term strategies, minimizing latency in data processing and order execution is paramount.

## 5. Project-Specific Instructions for Claude

This section provides specific operational and development guidelines for Claude, ensuring efficient interaction with the FNTX AI system and its components. Claude is expected to read all relevant Markdown files and documentation to maintain a comprehensive understanding of the project\'s context, purpose, and operational procedures.

### 5.1 Key Commands

To manage the FNTX AI system, the following key commands are essential:

*   **Start Development**: `./scripts/dev/start-dev.sh` - Initiates the frontend and backend development servers.
*   **Stop Development**: `./scripts/dev/stop-dev.sh` - Halts all running development services.

### 5.2 Key Data Sources

Critical data sources for the FNTX AI system include:

*   **Theta Terminal**: Provides extensive historical options data, with a target of 8 years of data for training and analysis.
*   **Interactive Brokers (IBKR)**: Serves as the primary source for live trade records and execution data.

### 5.3 Conventions

To ensure data consistency and accurate tracking across all components, the following convention must be adhered to:

*   **Standardized Time Format**: All time-related data across all databases and system components must use a standardized format, focusing on timesteps to enable precise tracking and synchronization of events.

### 5.4 Important Dates

Key historical dates for the FNTX AI project:

*   **Trading Started**: June 20, 2025
*   **Initial Deposit**: June 12, 2025

### 5.5 Project Structure and Contextual Understanding

Claude\'s operational efficiency is directly tied to its comprehensive understanding of the project\'s file structure and the purpose of each component. The project is organized as follows:

*   `backend/`: Contains the core AI agents and trading logic.
*   `frontend/`: Houses the React user interface components.
*   `scripts/`: A centralized location for all executable scripts, organized into subdirectories by function (e.g., `dev/`, `monitoring/`, `trade-logging/`). Claude is expected to utilize these scripts for various operational tasks.
*   `tools/ClaudePoint/`: This directory contains the checkpoint management tool, crucial for saving and restoring the state of the AI agents.
*   `database/`: While the actual data resides in PostgreSQL, this directory contains SQL migration scripts and related database configurations.
*   `docs/`: This directory contains comprehensive documentation, including setup guides, integration guides, and system overviews. Claude is specifically instructed to read and internalize the information within all `.md` files across the entire project, including `README.md` files in various subdirectories. This continuous contextual awareness will enable Claude to understand the \'why\' behind its actions, run the correct scripts, and efficiently locate necessary files and tools at any given moment, ensuring seamless operation and effective problem-solving.

## References
Paper 1.txt
Paper 2.txt
